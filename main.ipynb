{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "246373e8-7433-43ac-bf40-170e72425832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, random\n",
    "# print(sys.executable)\n",
    "# print(sys.version)\n",
    "import cv2\n",
    "import cvzone\n",
    "import pyautogui\n",
    "import mediapipe as mp\n",
    "from cvzone.HandTrackingModule import HandDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0a99d7-7e6d-4e58-b83c-ea5dad62158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_fingers_raised(lmList):\n",
    "\n",
    "    if len(lmList) != 21:\n",
    "        return False\n",
    "        \n",
    "    thumb_tip = 4\n",
    "    thumb_ip = 3\n",
    "    index_tip = 8\n",
    "    index_ip = 7\n",
    "    middle_tip = 12\n",
    "    middle_ip = 11\n",
    "    ring_tip = 16\n",
    "    ring_ip = 15\n",
    "    pinky_tip = 20\n",
    "    pinky_ip = 19\n",
    "    return (is_finger_raised(lmList, thumb_tip, thumb_ip) and\n",
    "            is_finger_raised(lmList, index_tip, index_ip) and\n",
    "            is_finger_raised(lmList, middle_tip, middle_ip) and\n",
    "            is_finger_raised(lmList, ring_tip, ring_ip) and\n",
    "            is_finger_raised(lmList, pinky_tip, pinky_ip))\n",
    "\n",
    "def is_finger_raised(lmList, tip, phalanx):\n",
    "    return lmList[tip][1] < lmList[phalanx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163e1d65-be65-434c-8cbb-c893017dc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_movement(lmList):\n",
    "    index_finger = lmList[8][:2]\n",
    "    middle_finger = lmList[12][:2]\n",
    "    distance = ((index_finger[0] - middle_finger[0])**2 + (index_finger[1] - middle_finger[1])**2)**0.5\n",
    "    x = int(index_finger[0] * screen_width / frame.shape[1])\n",
    "    y = int(index_finger[1] * screen_height / frame.shape[0])\n",
    "\n",
    "    # Move mouse cursor\n",
    "    pyautogui.moveTo(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0558004e-1526-4a9c-94eb-cec3ccb75061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, screen_width)\n",
    "    cap.set(4, screen_height)\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95489015-9edc-4b31-b56b-24bed5a8223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run():\n",
    "\n",
    "    hand_detector = HandDetector(detectionCon=0, maxHands=1)\n",
    "    screen_width, screen_height = pyautogui.size()\n",
    "    cap = set_camera()\n",
    "    while cap.isOpened() and running:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "    \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        hands, img = hand_detector.findHands(frame)\n",
    "    \n",
    "        if hands: \n",
    "            lmList = hands[0]['lmList']\n",
    "            \n",
    "            # stops the program\n",
    "            if all_fingers_raised(lmList):\n",
    "                break\n",
    "            \n",
    "            mouse_movement(lmList)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f1855f2-255e-44c3-bfb0-98f0793ecf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1726773866.414399   42094 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1726773866.416202   43454 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.3-1pop1~1711635559~22.04~7a9f319), renderer: Mesa Intel(R) UHD Graphics 620 (WHL GT2)\n",
      "W0000 00:00:1726773866.453489   43446 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1726773866.482540   43444 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/home/austin/projects/drag-and-drop/venv/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2669f2a-24ab-4c11-8002-0d461aba106d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
